[INFO 23:46:59] spectral_epymarl Running command 'my_main'
[INFO 23:46:59] spectral_epymarl Started run with ID "4"
[DEBUG 23:46:59] spectral_epymarl Starting Heartbeat
[DEBUG 23:46:59] my_main Started
[INFO 23:46:59] my_main Experiment Parameters:
[INFO 23:46:59] my_main 

{   'action_selector': 'soft_policies',
    'add_value_last_step': True,
    'agent': 'rnn',
    'agent_output_type': 'pi_logits',
    'batch_size': 10,
    'batch_size_run': 10,
    'buffer_cpu_only': True,
    'buffer_size': 10,
    'checkpoint_path': '',
    'critic_spectral': True,
    'critic_type': 'cv_critic',
    'entropy_coef': 0.001,
    'env': 'sc2',
    'env_args': {   'continuing_episode': False,
                    'debug': False,
                    'difficulty': '7',
                    'game_version': None,
                    'heuristic_ai': False,
                    'heuristic_rest': False,
                    'map_name': '3s_vs_5z',
                    'move_amount': 2,
                    'obs_all_health': True,
                    'obs_instead_of_state': False,
                    'obs_last_action': False,
                    'obs_own_health': True,
                    'obs_pathing_grid': False,
                    'obs_terrain_height': False,
                    'obs_timestep_number': False,
                    'replay_dir': '',
                    'replay_prefix': '',
                    'reward_death_value': 10,
                    'reward_defeat': 0,
                    'reward_negative_scale': 0.5,
                    'reward_only_positive': True,
                    'reward_scale': True,
                    'reward_scale_rate': 20,
                    'reward_sparse': False,
                    'reward_win': 200,
                    'seed': 1,
                    'state_last_action': False,
                    'state_timestep_number': False,
                    'step_mul': 8},
    'epochs': 4,
    'eps_clip': 0.2,
    'evaluate': False,
    'gamma': 0.99,
    'grad_norm_clip': 10,
    'hidden_dim': 128,
    'hypergroup': None,
    'label': 'default_label',
    'learner': 'ppo_learner',
    'learner_log_interval': 10000,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 50000,
    'lr': 0.0005,
    'mac': 'basic_mac',
    'mask_before_softmax': True,
    'name': 'spectralNorm_cs_mappo',
    'obs_agent_id': True,
    'obs_individual_obs': False,
    'obs_last_action': False,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'policy_spectral': False,
    'q_nstep': 10,
    'repeat_id': 1,
    'rnn_spectral': False,
    'runner': 'parallel',
    'runner_log_interval': 10000,
    'save_model': True,
    'save_model_interval': 1000000,
    'save_replay': False,
    'seed': 1,
    'spectral_regularization': False,
    'standardise_returns': False,
    'standardise_rewards': False,
    't_max': 40050000,
    'target_update_interval_or_tau': 0.01,
    'test_greedy': True,
    'test_interval': 1000000,
    'test_nepisode': 100,
    'use_cuda': True,
    'use_rnn': True,
    'use_tensorboard': True,
    'use_wandb': True,
    'wandb_entity': 'kinalmehta',
    'wandb_project': 'marl-spectral'}

[DEBUG 23:47:01] wandb.wandb_config no defaults not found in config-defaults.yaml
wandb: W&B is a tool that helps track and visualize machine learning experiments
wandb: No credentials found.  Run "wandb login" to visualize your metrics
wandb: Tracking run with wandb version 0.9.7
wandb: Wandb version 0.13.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Run data is saved locally in wandb/run-20220813_234701-f78usfq6

